{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3409be1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "PyTorch version: 2.1.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4788e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN CSV (first 5 rows) ===\n",
      "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
      "0  ISIC_0024306  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "1  ISIC_0024307  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "2  ISIC_0024308  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "3  ISIC_0024309  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "4  ISIC_0024310  1.0  0.0  0.0    0.0  0.0  0.0   0.0\n",
      "Train CSV has 10015 entries\n",
      "\n",
      "=== VAL CSV (first 5 rows) ===\n",
      "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
      "0  ISIC_0034321  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "1  ISIC_0034322  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "2  ISIC_0034323  0.0  0.0  1.0    0.0  0.0  0.0   0.0\n",
      "3  ISIC_0034324  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "4  ISIC_0034325  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "Val CSV has 193 entries\n",
      "\n",
      "=== TEST CSV (first 5 rows) ===\n",
      "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
      "0  ISIC_0034524  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "1  ISIC_0034525  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "2  ISIC_0034526  0.0  0.0  0.0    0.0  1.0  0.0   0.0\n",
      "3  ISIC_0034527  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "4  ISIC_0034528  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
      "Test CSV has 1512 entries\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configure Paths & Validate Files\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configure paths\n",
    "PATH_TRAIN_CSV = r\"D:\\ISIC2018\\GroundTruth\\Training_GrounTruth\\ISIC2018_Task3_Training_GroundTruth.csv\"\n",
    "PATH_VAL_CSV = r\"D:\\ISIC2018\\GroundTruth\\Validation_GroundTruth\\ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
    "PATH_TEST_CSV = r\"D:\\ISIC2018\\GroundTruth\\Test_GroundTruth\\ISIC2018_Task3_Test_GroundTruth.csv\"\n",
    "\n",
    "# Image directories\n",
    "DIR_TRAIN_IMG = r\"D:\\ISIC2018\\Training_Input\"\n",
    "DIR_VAL_IMG = r\"D:\\ISIC2018\\Validation_Input\"\n",
    "DIR_TEST_IMG = r\"D:\\ISIC2018\\Test_Input\"\n",
    "\n",
    "PATH_LESION_GROUPINGS = r\"D:\\ISIC2018\\Training_LesionGroupings.csv\"\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(\"outputs/models\", exist_ok=True)\n",
    "os.makedirs(\"outputs/submissions\", exist_ok=True)\n",
    "os.makedirs(\"outputs/figures\", exist_ok=True)\n",
    "\n",
    "\n",
    "# Read and preview CSVs\n",
    "print(\"\\n=== TRAIN CSV (first 5 rows) ===\")\n",
    "df_train_raw = pd.read_csv(PATH_TRAIN_CSV)\n",
    "print(df_train_raw.head())\n",
    "print(f\"Train CSV has {len(df_train_raw)} entries\")\n",
    "\n",
    "print(\"\\n=== VAL CSV (first 5 rows) ===\")\n",
    "df_val_raw = pd.read_csv(PATH_VAL_CSV)\n",
    "print(df_val_raw.head())\n",
    "print(f\"Val CSV has {len(df_val_raw)} entries\")\n",
    "\n",
    "print(\"\\n=== TEST CSV (first 5 rows) ===\")\n",
    "df_test_raw = pd.read_csv(PATH_TEST_CSV)\n",
    "print(df_test_raw.head())\n",
    "print(f\"Test CSV has {len(df_test_raw)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7a86ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAIN DATASET ===\n",
      "Total samples: 10015\n",
      "\n",
      "Label distribution:\n",
      "  AKIEC: 327 (3.27%)\n",
      "  BCC: 514 (5.13%)\n",
      "  BKL: 1099 (10.97%)\n",
      "  DF: 115 (1.15%)\n",
      "  MEL: 1113 (11.11%)\n",
      "  NV: 6705 (66.95%)\n",
      "  VASC: 142 (1.42%)\n",
      "\n",
      "=== VAL DATASET ===\n",
      "Total samples: 193\n",
      "\n",
      "Label distribution:\n",
      "  AKIEC: 8 (4.15%)\n",
      "  BCC: 15 (7.77%)\n",
      "  BKL: 22 (11.40%)\n",
      "  DF: 1 (0.52%)\n",
      "  MEL: 21 (10.88%)\n",
      "  NV: 123 (63.73%)\n",
      "  VASC: 3 (1.55%)\n",
      "\n",
      "=== TEST DATASET ===\n",
      "Total samples: 1512\n",
      "\n",
      "Label distribution:\n",
      "  AKIEC: 43 (2.84%)\n",
      "  BCC: 93 (6.15%)\n",
      "  BKL: 217 (14.35%)\n",
      "  DF: 44 (2.91%)\n",
      "  MEL: 171 (11.31%)\n",
      "  NV: 909 (60.12%)\n",
      "  VASC: 35 (2.31%)\n",
      "\n",
      "=== LABEL MAPPING ===\n",
      "Number of classes: 7\n",
      "  0: AKIEC\n",
      "  1: BCC\n",
      "  2: BKL\n",
      "  3: DF\n",
      "  4: MEL\n",
      "  5: NV\n",
      "  6: VASC\n",
      "\n",
      "Class imbalance ratio: 58.30\n",
      "âš  High class imbalance detected. Will use WeightedRandomSampler.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Parse Ground Truth & Create Label Mapping\n",
    "def parse_ground_truth(df_raw, img_dir, split_name=\"train\"):\n",
    "\n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    # Detect image_id column (first column or contains 'image')\n",
    "    img_col = df.columns[0]\n",
    "    \n",
    "    # Detect label columns (one-hot encoded or single label column)\n",
    "    # ISIC2018 Task 3 uses one-hot encoding for 7 disease categories\n",
    "    potential_label_cols = [col for col in df.columns if col != img_col]\n",
    "    \n",
    "    # Check if one-hot encoded (multiple binary columns)\n",
    "    if len(potential_label_cols) > 1 and df[potential_label_cols].isin([0, 1]).all().all():\n",
    "        # One-hot encoded: find the column with 1\n",
    "        df['label'] = df[potential_label_cols].idxmax(axis=1)\n",
    "    else:\n",
    "        # Single label column\n",
    "        df['label'] = df[potential_label_cols[0]]\n",
    "    \n",
    "    # Create image_id and image_path\n",
    "    df['image_id'] = df[img_col].astype(str)\n",
    "    df['image_path'] = df['image_id'].apply(lambda x: os.path.join(img_dir, f\"{x}.jpg\"))\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df_clean = df[['image_id', 'label', 'image_path']].copy()\n",
    "    \n",
    "    print(f\"\\n=== {split_name.upper()} DATASET ===\")\n",
    "    print(f\"Total samples: {len(df_clean)}\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    label_counts = df_clean['label'].value_counts().sort_index()\n",
    "    for label, count in label_counts.items():\n",
    "        pct = 100 * count / len(df_clean)\n",
    "        print(f\"  {label}: {count} ({pct:.2f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Parse all splits\n",
    "df_train = parse_ground_truth(df_train_raw, DIR_TRAIN_IMG, \"train\")\n",
    "df_val = parse_ground_truth(df_val_raw, DIR_VAL_IMG, \"val\")\n",
    "df_test = parse_ground_truth(df_test_raw, DIR_TEST_IMG, \"test\")\n",
    "\n",
    "# Create label mapping\n",
    "all_labels = sorted(df_train['label'].unique())\n",
    "label2idx = {label: idx for idx, label in enumerate(all_labels)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "num_classes = len(all_labels)\n",
    "\n",
    "print(f\"\\n=== LABEL MAPPING ===\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "for label, idx in label2idx.items():\n",
    "    print(f\"  {idx}: {label}\")\n",
    "\n",
    "# Apply label mapping\n",
    "df_train['label_idx'] = df_train['label'].map(label2idx)\n",
    "df_val['label_idx'] = df_val['label'].map(label2idx)\n",
    "df_test['label_idx'] = df_test['label'].map(label2idx)\n",
    "\n",
    "# Check for class imbalance\n",
    "train_label_counts = df_train['label_idx'].value_counts().sort_index()\n",
    "max_count = train_label_counts.max()\n",
    "min_count = train_label_counts.min()\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "if imbalance_ratio > 3:\n",
    "    print(\"âš  High class imbalance detected. Will use WeightedRandomSampler.\")\n",
    "    USE_WEIGHTED_SAMPLER = True\n",
    "else:\n",
    "    USE_WEIGHTED_SAMPLER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bd5975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Class\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['image_path']\n",
    "        label = row['label_idx']\n",
    "        image_id = row['image_id']\n",
    "        \n",
    "        # Load image\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, torch.tensor(label, dtype=torch.long), image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe990d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train transforms: Compose(\n",
      "    Resize(size=320, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    RandomResizedCrop(size=(300, 300), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-20.0, 20.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.05, 0.05))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "Val/Test transforms: Compose(\n",
      "    Resize(size=320, interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    CenterCrop(size=(300, 300))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Transforms\n",
    "# EfficientNet-B3 default input size is 300\n",
    "IMG_SIZE = 300\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Train transforms with augmentation\n",
    "train_transform = T.Compose([\n",
    "    T.Resize(320),\n",
    "    T.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    T.RandomRotation(20),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),  # Giáº£m hue tá»« 0.1 xuá»‘ng 0.05\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Val/Test transforms without augmentation\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(320),\n",
    "    T.CenterCrop(IMG_SIZE),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"Train transforms:\", train_transform)\n",
    "print(\"\\nVal/Test transforms:\", val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4709f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 10015\n",
      "Val dataset size: 193\n",
      "Test dataset size: 1512\n",
      "Using WeightedRandomSampler for balanced sampling\n",
      "\n",
      "Batch size: 8\n",
      "Train batches: 1252\n",
      "Val batches: 25\n",
      "Test batches: 189\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: DataLoaders\n",
    "# Batch size configuration\n",
    "BATCH_SIZE = 16 if torch.cuda.is_available() else 8\n",
    "NUM_WORKERS = 0  # Set to 0 for Windows to avoid issues\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ISICDataset(df_train, transform=train_transform)\n",
    "val_dataset = ISICDataset(df_val, transform=val_transform)\n",
    "test_dataset = ISICDataset(df_test, transform=val_transform)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Val dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Create WeightedRandomSampler if imbalanced\n",
    "if USE_WEIGHTED_SAMPLER:\n",
    "    class_counts = df_train['label_idx'].value_counts().sort_index().values\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = [class_weights[label] for label in df_train['label_idx']]\n",
    "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "    shuffle = False\n",
    "    print(\"Using WeightedRandomSampler for balanced sampling\")\n",
    "else:\n",
    "    sampler = None\n",
    "    shuffle = True\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler,\n",
    "    shuffle=shuffle,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f854c559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: EfficientNet-B3\n",
      "Total parameters: 10,706,991\n",
      "Trainable parameters: 10,706,991\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Model Architecture\n",
    "def build_model(num_classes, pretrained=True):\n",
    "    \"\"\"Build EfficientNet-B3 model with custom classifier.\"\"\"\n",
    "    model = timm.create_model('efficientnet_b3', pretrained=pretrained, num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = build_model(num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: EfficientNet-B3\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d258bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CrossEntropyLoss\n",
      "Optimizer: AdamW (lr=0.0003, weight_decay=0.0001)\n",
      "Scheduler: CosineAnnealingLR (T_max=15)\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Loss, Optimizer, Scheduler\n",
    "# Configuration\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "USE_LABEL_SMOOTHING = False  # Set to True if desired\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# Loss function\n",
    "if USE_LABEL_SMOOTHING:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "    print(f\"Using CrossEntropyLoss with label smoothing: {LABEL_SMOOTHING}\")\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(\"Using CrossEntropyLoss\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "print(f\"Optimizer: AdamW (lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY})\")\n",
    "\n",
    "# Scheduler\n",
    "USE_COSINE_SCHEDULER = True  # Set to False to use ReduceLROnPlateau\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "if USE_COSINE_SCHEDULER:\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=NUM_EPOCHS, eta_min=1e-6\n",
    "    )\n",
    "    print(f\"Scheduler: CosineAnnealingLR (T_max={NUM_EPOCHS})\")\n",
    "else:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    print(\"Scheduler: ReduceLROnPlateau (mode=max, factor=0.5, patience=2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluation functions defined.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Cell 9: Train & Evaluation Functions\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels, _ in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training\n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation/test set.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    all_image_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, image_ids in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_image_ids.extend(image_ids)\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    epoch_bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_f1, epoch_bal_acc, all_preds, all_labels, all_probs, all_image_ids\n",
    "\n",
    "\n",
    "print(\"Train and evaluation functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe06c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ†• Starting fresh training (no checkpoint found)\n",
      "\n",
      "Starting training for 15 epochs (from epoch 1)...\n",
      "Early stopping: patience=3, monitor=val_f1\n",
      "\n",
      "\n",
      "Epoch 1/15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da64251c8f846b2bdd60f0382e98e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1252 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10: Training Loop with Checkpoint Resume\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "# Training configuration\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "MONITOR_METRIC = 'val_f1'\n",
    "MODEL_PATH = 'outputs/models/efficientnet_b3_isic2018.pt'\n",
    "\n",
    "# Initialize mixed precision scaler\n",
    "scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'epoch': [], 'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [], 'val_bal_acc': [], 'lr': []\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_val_f1 = 0.0\n",
    "best_epoch = 0\n",
    "patience_counter = 0\n",
    "start_epoch = 0\n",
    "\n",
    "# ========== LOAD EXISTING CHECKPOINT IF EXISTS ==========\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(f\"ðŸ“‚ Found existing checkpoint: {MODEL_PATH}\")\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint.get('epoch', 0)\n",
    "    best_val_f1 = checkpoint.get('best_val_f1', 0.0)\n",
    "    best_epoch = checkpoint.get('best_epoch', 0)\n",
    "    if 'history' in checkpoint:\n",
    "        history = checkpoint['history']\n",
    "    print(f\"âœ“ Resumed from epoch {start_epoch}, best F1: {best_val_f1:.4f}\")\n",
    "else:\n",
    "    print(\"ðŸ†• Starting fresh training (no checkpoint found)\")\n",
    "\n",
    "print(f\"\\nStarting training for {NUM_EPOCHS} epochs (from epoch {start_epoch + 1})...\")\n",
    "print(f\"Early stopping: patience={EARLY_STOP_PATIENCE}, monitor={MONITOR_METRIC}\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Train with progress bar\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Training\", leave=True)\n",
    "    for images, labels, _ in train_pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler is not None:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, val_bal_acc, _, _, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    if USE_COSINE_SCHEDULER:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        scheduler.step(val_f1)\n",
    "    \n",
    "    # Record history\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['val_bal_acc'].append(val_bal_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Check for best model and ALWAYS save checkpoint\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        print(f\"âœ“ New best model! (F1: {val_f1:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{EARLY_STOP_PATIENCE}\")\n",
    "    \n",
    "    # ========== SAVE CHECKPOINT (ALWAYS UPDATE) ==========\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'best_epoch': best_epoch,\n",
    "        'val_f1': val_f1,\n",
    "        'val_acc': val_acc,\n",
    "        'history': history,\n",
    "        'label2idx': label2idx,\n",
    "        'idx2label': idx2label,\n",
    "        'num_classes': num_classes,\n",
    "    }, MODEL_PATH)\n",
    "    print(f\"ðŸ’¾ Checkpoint saved: {MODEL_PATH}\")\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "        print(f\"\\n Early stopping triggered at epoch {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"âœ… Training completed!\")\n",
    "print(f\"ðŸ“Š Best epoch: {best_epoch} with Val F1: {best_val_f1:.4f}\")\n",
    "print(f\"ðŸ“ Model saved: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d0558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs/models/best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 11: Evaluate on Validation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading best model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutputs/models/best_model.pth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m model.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded model from epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with best metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint[\u001b[33m'\u001b[39m\u001b[33mbest_metric\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:986\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m    984\u001b[39m     pickle_load_args[\u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m    989\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m    990\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m    991\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:435\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    437\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:416\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'outputs/models/best_model.pth'"
     ]
    }
   ],
   "source": [
    "# Cell 11: Evaluate on Validation\n",
    "# Load best model\n",
    "print(\"Loading best model...\")\n",
    "checkpoint = torch.load('outputs/models/best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded model from epoch {checkpoint['epoch']} with best metric: {checkpoint['best_metric']:.4f}\\n\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"Evaluating on validation set...\")\n",
    "val_loss, val_acc, val_f1, val_bal_acc, val_preds, val_labels, val_probs, val_image_ids = evaluate(\n",
    "    model, val_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"Validation Results:\")\n",
    "print(f\"  Loss: {val_loss:.4f}\")\n",
    "print(f\"  Accuracy: {val_acc:.4f}\")\n",
    "print(f\"  Macro F1: {val_f1:.4f}\")\n",
    "print(f\"  Balanced Accuracy: {val_bal_acc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_labels, val_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[idx2label[i] for i in range(num_classes)],\n",
    "            yticklabels=[idx2label[i] for i in range(num_classes)])\n",
    "plt.title('Validation Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/val_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(val_labels, val_preds, \n",
    "                          target_names=[idx2label[i] for i in range(num_classes)],\n",
    "                          digits=4))\n",
    "\n",
    "# Show misclassified examples\n",
    "print(\"\\n=== Misclassified Examples ===\")\n",
    "val_results_df = pd.DataFrame({\n",
    "    'image_id': val_image_ids,\n",
    "    'true_label': val_labels,\n",
    "    'pred_label': val_preds,\n",
    "})\n",
    "val_results_df['true_class'] = val_results_df['true_label'].map(idx2label)\n",
    "val_results_df['pred_class'] = val_results_df['pred_label'].map(idx2label)\n",
    "val_results_df['correct'] = val_results_df['true_label'] == val_results_df['pred_label']\n",
    "\n",
    "misclassified = val_results_df[~val_results_df['correct']].head(16)\n",
    "print(f\"Found {len(val_results_df[~val_results_df['correct']])} misclassified images\")\n",
    "\n",
    "if len(misclassified) > 0:\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (_, row) in enumerate(misclassified.iterrows()):\n",
    "        if idx >= 16:\n",
    "            break\n",
    "        \n",
    "        img_path = os.path.join(DIR_VAL_IMG, f\"{row['image_id']}.jpg\")\n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f\"True: {row['true_class']}\\nPred: {row['pred_class']}\", \n",
    "                               fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/figures/val_misclassified.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Evaluate on Test\n",
    "# Evaluate on test set\n",
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_acc, test_f1, test_bal_acc, test_preds, test_labels, test_probs, test_image_ids = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Macro F1: {test_f1:.4f}\")\n",
    "print(f\"  Balanced Accuracy: {test_bal_acc:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm_test = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=[idx2label[i] for i in range(num_classes)],\n",
    "            yticklabels=[idx2label[i] for i in range(num_classes)])\n",
    "plt.title('Test Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/test_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\n=== Test Classification Report ===\")\n",
    "print(classification_report(test_labels, test_preds,\n",
    "                          target_names=[idx2label[i] for i in range(num_classes)],\n",
    "                          digits=4))\n",
    "\n",
    "# Create submission file\n",
    "submission_data = {\n",
    "    'image_id': test_image_ids,\n",
    "    'predicted_label': [idx2label[pred] for pred in test_preds],\n",
    "}\n",
    "\n",
    "# Add probability columns for each class\n",
    "for i in range(num_classes):\n",
    "    submission_data[f'prob_{idx2label[i]}'] = [probs[i] for probs in test_probs]\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_path = 'outputs/submissions/test_predictions.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"\\nSubmission file saved to: {submission_path}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Inference Demo\n",
    "def predict_image(model, image_path, transform, device, idx2label, top_k=3):\n",
    "    \"\"\"Predict single image and return top-k predictions.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probs = F.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    top_k_indices = np.argsort(probs)[::-1][:top_k]\n",
    "    top_k_probs = probs[top_k_indices]\n",
    "    top_k_labels = [idx2label[idx] for idx in top_k_indices]\n",
    "    \n",
    "    return image, top_k_labels, top_k_probs\n",
    "\n",
    "\n",
    "# Demo images\n",
    "demo_images = [\n",
    "    (r\"D:\\ISIC2018\\Test_Input\\ISIC_0034524.jpg\", \"ISIC_0034524\"),\n",
    "    (r\"D:\\ISIC2018\\Validation_Input\\ISIC_0034321.jpg\", \"ISIC_0034321\"),\n",
    "]\n",
    "\n",
    "print(\"=== Inference Demo ===\\n\")\n",
    "\n",
    "fig, axes = plt.subplots(1, len(demo_images), figsize=(12, 5))\n",
    "if len(demo_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (img_path, img_name) in enumerate(demo_images):\n",
    "    if os.path.exists(img_path):\n",
    "        image, top_labels, top_probs = predict_image(\n",
    "            model, img_path, val_transform, device, idx2label, top_k=3\n",
    "        )\n",
    "        \n",
    "        # Display\n",
    "        axes[idx].imshow(image)\n",
    "        title = f\"{img_name}\\n\"\n",
    "        for i, (label, prob) in enumerate(zip(top_labels, top_probs)):\n",
    "            title += f\"{i+1}. {label}: {prob:.3f}\\n\"\n",
    "        axes[idx].set_title(title, fontsize=9)\n",
    "        axes[idx].axis('off')\n",
    "        \n",
    "        # Print to console\n",
    "        print(f\"Image: {img_name}\")\n",
    "        for i, (label, prob) in enumerate(zip(top_labels, top_probs)):\n",
    "            print(f\"  {i+1}. {label}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"Image not found: {img_path}\\n\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/figures/inference_demo.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Inference demo completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
